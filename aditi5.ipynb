{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103417,"databundleVersionId":12473839,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# --------------------------------------------------------\n# 1. LOAD DATA\n# --------------------------------------------------------\ntrain_path = \"/kaggle/input/mock-test-2-mse-2/train.csv\"\ntest_path = \"/kaggle/input/mock-test-2-mse-2/test.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\n# --------------------------------------------------------\n# 2. SEPARATE FEATURES & TARGET\n# --------------------------------------------------------\ny = train_df[\"Status\"]\nX = train_df.drop(columns=[\"Status\"])\n\ntest_ids = test_df[\"id\"]\nX_test = test_df.copy()\n\n# --------------------------------------------------------\n# 3. IDENTIFY COLUMN TYPES\n# --------------------------------------------------------\nnum_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n\nif \"id\" in num_cols: num_cols.remove(\"id\")\nif \"id\" in cat_cols: cat_cols.remove(\"id\")\n\n# --------------------------------------------------------\n# 4. VISUALIZATIONS\n# --------------------------------------------------------\nfor col in num_cols[:5]:\n    plt.figure(figsize=(5,3))\n    plt.hist(X[col].dropna(), bins=30)\n    plt.title(f\"Histogram - {col}\")\n    plt.tight_layout()\n    plt.show()\n\nplt.figure(figsize=(10,6))\nsns.heatmap(X[num_cols].corr(), annot=False)\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\n# --------------------------------------------------------\n# 5. OUTLIER CAPPING (with warnings ignored)\n# --------------------------------------------------------\ndef cap_outliers(df, cols):\n    df = df.copy()\n    for col in cols:\n        Q1 = df[col].quantile(0.25)\n        Q3 = df[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower = Q1 - 1.5 * IQR\n        upper = Q3 + 1.5 * IQR\n        # Ignore runtime warnings for NaN or invalid comparisons\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            df[col] = df[col].clip(lower, upper)\n    return df\n\nfor col in num_cols:\n    X[col] = cap_outliers(X[[col]], [col])[col]\n    X_test[col] = cap_outliers(X_test[[col]], [col])[col]\n\n# --------------------------------------------------------\n# 6. PREPROCESSING PIPELINE\n# --------------------------------------------------------\nnumeric_tf = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\"))\n])\n\ncategorical_tf = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocess = ColumnTransformer([\n    (\"num\", numeric_tf, num_cols),\n    (\"cat\", categorical_tf, cat_cols)\n])\n\n# --------------------------------------------------------\n# 7. FINAL MODEL (RandomForest)\n# --------------------------------------------------------\nmodel = Pipeline([\n    (\"preprocess\", preprocess),\n    (\"rf\", RandomForestClassifier(\n        n_estimators=500,\n        max_depth=25,\n        min_samples_split=3,\n        min_samples_leaf=1,\n        max_features='sqrt',\n        bootstrap=True,\n        random_state=42,\n        class_weight=\"balanced\"\n    ))\n])\n\n# --------------------------------------------------------\n# 8. TRAIN/VALIDATION SPLIT\n# --------------------------------------------------------\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# --------------------------------------------------------\n# 9. TRAIN MODEL\n# --------------------------------------------------------\nmodel.fit(X_train, y_train)\n\n# --------------------------------------------------------\n# 10. VALIDATION ACCURACY\n# --------------------------------------------------------\npreds = model.predict(X_valid)\nprint(\"Validation Accuracy:\", accuracy_score(y_valid, preds))\n\n# --------------------------------------------------------\n# 11. PREDICT TEST PROBABILITIES\n# --------------------------------------------------------\nprobs = model.predict_proba(X_test)\nclass_order = model.named_steps[\"rf\"].classes_\n\n# --------------------------------------------------------\n# 12. SAVE SUBMISSION\n# --------------------------------------------------------\nsubmission = pd.DataFrame()\nsubmission[\"id\"] = test_ids\nsubmission[\"Status_C\"]  = probs[:, list(class_order).index(\"C\")]\nsubmission[\"Status_CL\"] = probs[:, list(class_order).index(\"CL\")]\nsubmission[\"Status_D\"]  = probs[:, list(class_order).index(\"D\")]\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv generated successfully!\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T03:50:20.771464Z","iopub.execute_input":"2025-11-21T03:50:20.771891Z","iopub.status.idle":"2025-11-21T03:50:37.155807Z","shell.execute_reply.started":"2025-11-21T03:50:20.771860Z","shell.execute_reply":"2025-11-21T03:50:37.154915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}